{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torchvision.io as io\n",
    "import os\n",
    "\n",
    "# Define your device (for GPU processing)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    # transforms.ToPILImage(),\n",
    "    transforms.Resize((128, 128)),  # Resize frames to 128x128\n",
    "    transforms.ToTensor(),  # Convert frames to tensor format\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize the RGB channels\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class VideoDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None, max_frames=400, myframes = 0):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.max_frames = max_frames  # Maximum frames to load\n",
    "        self.myframes = myframes\n",
    "        self.classes = ['non_violent', 'violent']\n",
    "        self.data = []\n",
    "        \n",
    "        for label, class_name in enumerate(self.classes):\n",
    "            class_dir = os.path.join(root_dir, class_name)\n",
    "            for cam_folder in os.listdir(class_dir):\n",
    "                cam_dir = os.path.join(class_dir, cam_folder)\n",
    "                if os.path.isdir(cam_dir):  \n",
    "                    for video_name in os.listdir(cam_dir):\n",
    "                        if video_name.endswith('.mp4'):\n",
    "                            video_path = os.path.join(cam_dir, video_name)\n",
    "                            self.data.append((video_path, label)) \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        video_path, label = self.data[idx]\n",
    "        \n",
    "        # Load the video and all its frames\n",
    "        video, _, _ = io.read_video(video_path, pts_unit='sec')\n",
    "\n",
    "        # Print original shape\n",
    "        # print(f\"Original video shape: {video.shape}\")\n",
    "        self.myframes = self.myframes + video.shape[0]\n",
    "        # Number of frames in the video\n",
    "        total_frames = video.shape[0]\n",
    "\n",
    "        # Initialize the padded tensor\n",
    "        if total_frames < self.max_frames:\n",
    "            # Create a new tensor filled with zeros\n",
    "            padded_video = torch.zeros((self.max_frames, video.shape[1], video.shape[2], video.shape[3]), dtype=video.dtype)\n",
    "            # Copy the existing frames into the padded tensor\n",
    "            padded_video[:total_frames] = video  # Fill the start with actual frames\n",
    "            video = padded_video  # Use the padded video\n",
    "        else:\n",
    "            # If we have enough frames, just take the first max_frames\n",
    "            video = video[:self.max_frames]\n",
    "\n",
    "        # Print shape after padding/truncating\n",
    "        # print(f\"Processed video shape: {video.shape}\")\n",
    "\n",
    "        # Apply transformations to each frame\n",
    "        pil_transform = transforms.ToPILImage()\n",
    "        frames = []\n",
    "        for frame in video:\n",
    "            # Convert to [channels, height, width]\n",
    "            frame = frame.permute(2, 0, 1)  # Swap dimensions\n",
    "\n",
    "            pil_img = pil_transform(frame)  # Convert to PIL\n",
    "            if self.transform:\n",
    "                pil_img = self.transform(pil_img)  # Apply transformation\n",
    "            frames.append(pil_img)\n",
    "        \n",
    "        video = torch.stack(frames)  # Stack the frames back into a tensor\n",
    "        video = video.to(device)\n",
    "        label = torch.tensor(label).to(device)\n",
    "        print(self.myframes)\n",
    "        return video, label\n",
    "    def avg_frames(self):\n",
    "        return self.myframes / len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113\n",
      "249\n",
      "428\n",
      "502\n",
      "636\n",
      "torch.Size([5, 400, 3, 128, 128])\n",
      "tensor([1, 1, 1, 0, 0], device='cuda:0')\n",
      "781\n",
      "931\n",
      "1141\n",
      "1277\n",
      "1388\n",
      "torch.Size([5, 400, 3, 128, 128])\n",
      "tensor([1, 0, 1, 1, 1], device='cuda:0')\n",
      "1578\n",
      "1758\n",
      "1938\n",
      "2040\n",
      "2143\n",
      "torch.Size([5, 400, 3, 128, 128])\n",
      "tensor([1, 1, 1, 0, 1], device='cuda:0')\n",
      "2245\n",
      "2396\n",
      "2568\n",
      "2842\n",
      "3014\n",
      "torch.Size([5, 400, 3, 128, 128])\n",
      "tensor([0, 1, 1, 1, 0], device='cuda:0')\n",
      "3155\n",
      "3281\n",
      "3437\n",
      "3625\n",
      "3876\n",
      "torch.Size([5, 400, 3, 128, 128])\n",
      "tensor([0, 1, 1, 0, 1], device='cuda:0')\n",
      "4076\n",
      "4160\n",
      "4339\n",
      "4569\n",
      "4785\n",
      "torch.Size([5, 400, 3, 128, 128])\n",
      "tensor([1, 1, 1, 0, 1], device='cuda:0')\n",
      "4950\n",
      "5107\n",
      "5402\n",
      "5593\n",
      "5731\n",
      "torch.Size([5, 400, 3, 128, 128])\n",
      "tensor([0, 1, 1, 0, 1], device='cuda:0')\n",
      "5878\n",
      "5991\n",
      "6215\n",
      "6458\n",
      "6688\n",
      "torch.Size([5, 400, 3, 128, 128])\n",
      "tensor([0, 1, 0, 0, 0], device='cuda:0')\n",
      "6815\n",
      "7007\n",
      "7177\n",
      "7369\n",
      "7480\n",
      "torch.Size([5, 400, 3, 128, 128])\n",
      "tensor([1, 1, 1, 0, 0], device='cuda:0')\n",
      "7618\n",
      "7751\n",
      "7909\n",
      "8014\n",
      "8174\n",
      "torch.Size([5, 400, 3, 128, 128])\n",
      "tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "8332\n",
      "8439\n",
      "8555\n",
      "8691\n",
      "9041\n",
      "torch.Size([5, 400, 3, 128, 128])\n",
      "tensor([0, 0, 1, 1, 1], device='cuda:0')\n",
      "9210\n",
      "9327\n",
      "9483\n",
      "9651\n",
      "9802\n",
      "torch.Size([5, 400, 3, 128, 128])\n",
      "tensor([1, 1, 1, 1, 0], device='cuda:0')\n",
      "10021\n",
      "10245\n",
      "10416\n",
      "10607\n",
      "10841\n",
      "torch.Size([5, 400, 3, 128, 128])\n",
      "tensor([1, 0, 1, 0, 1], device='cuda:0')\n",
      "11018\n",
      "11219\n",
      "11378\n",
      "11560\n",
      "11781\n",
      "torch.Size([5, 400, 3, 128, 128])\n",
      "tensor([0, 0, 0, 1, 1], device='cuda:0')\n",
      "11963\n",
      "12131\n",
      "12224\n",
      "12362\n",
      "12544\n",
      "torch.Size([5, 400, 3, 128, 128])\n",
      "tensor([1, 1, 0, 0, 1], device='cuda:0')\n",
      "12694\n",
      "12859\n",
      "13008\n",
      "13118\n",
      "13224\n",
      "torch.Size([5, 400, 3, 128, 128])\n",
      "tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "13326\n",
      "13515\n",
      "13659\n",
      "13859\n",
      "14093\n",
      "torch.Size([5, 400, 3, 128, 128])\n",
      "tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "14462\n",
      "14648\n",
      "14783\n",
      "14879\n",
      "15154\n",
      "torch.Size([5, 400, 3, 128, 128])\n",
      "tensor([0, 1, 1, 1, 1], device='cuda:0')\n",
      "15428\n",
      "15587\n",
      "15717\n",
      "15877\n",
      "16046\n",
      "torch.Size([5, 400, 3, 128, 128])\n",
      "tensor([1, 0, 1, 1, 0], device='cuda:0')\n",
      "16336\n",
      "16495\n",
      "16648\n",
      "16762\n",
      "16871\n",
      "torch.Size([5, 400, 3, 128, 128])\n",
      "tensor([1, 0, 0, 1, 0], device='cuda:0')\n",
      "17011\n",
      "17141\n",
      "17273\n",
      "17437\n",
      "17671\n",
      "torch.Size([5, 400, 3, 128, 128])\n",
      "tensor([1, 0, 1, 0, 0], device='cuda:0')\n",
      "17907\n",
      "18147\n",
      "18345\n",
      "18446\n",
      "18615\n",
      "torch.Size([5, 400, 3, 128, 128])\n",
      "tensor([0, 1, 0, 0, 1], device='cuda:0')\n",
      "18716\n",
      "18943\n",
      "19122\n",
      "19228\n",
      "19420\n",
      "torch.Size([5, 400, 3, 128, 128])\n",
      "tensor([0, 1, 0, 1, 0], device='cuda:0')\n",
      "19494\n",
      "19658\n",
      "19848\n",
      "20040\n",
      "20205\n",
      "torch.Size([5, 400, 3, 128, 128])\n",
      "tensor([0, 0, 1, 0, 1], device='cuda:0')\n",
      "20292\n",
      "20418\n",
      "20543\n",
      "20667\n",
      "21017\n",
      "torch.Size([5, 400, 3, 128, 128])\n",
      "tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "21190\n",
      "21527\n",
      "21668\n",
      "21860\n",
      "22048\n",
      "torch.Size([5, 400, 3, 128, 128])\n",
      "tensor([1, 1, 1, 0, 0], device='cuda:0')\n",
      "22179\n",
      "22281\n",
      "22437\n",
      "22615\n",
      "22708\n",
      "torch.Size([5, 400, 3, 128, 128])\n",
      "tensor([0, 1, 1, 1, 0], device='cuda:0')\n",
      "23142\n",
      "23291\n",
      "23477\n",
      "23626\n",
      "23787\n",
      "torch.Size([5, 400, 3, 128, 128])\n",
      "tensor([1, 0, 1, 1, 1], device='cuda:0')\n",
      "24061\n",
      "24182\n",
      "24308\n",
      "24549\n",
      "24708\n",
      "torch.Size([5, 400, 3, 128, 128])\n",
      "tensor([1, 1, 1, 1, 0], device='cuda:0')\n",
      "24898\n",
      "25039\n",
      "25366\n",
      "25468\n",
      "25626\n",
      "torch.Size([5, 400, 3, 128, 128])\n",
      "tensor([1, 0, 1, 1, 1], device='cuda:0')\n",
      "25840\n",
      "25959\n",
      "26081\n",
      "26203\n",
      "26477\n",
      "torch.Size([5, 400, 3, 128, 128])\n",
      "tensor([1, 0, 0, 1, 1], device='cuda:0')\n",
      "26706\n",
      "26833\n",
      "27025\n",
      "27114\n",
      "27254\n",
      "torch.Size([5, 400, 3, 128, 128])\n",
      "tensor([1, 1, 0, 1, 1], device='cuda:0')\n",
      "27424\n",
      "27531\n",
      "27661\n",
      "27821\n",
      "27943\n",
      "torch.Size([5, 400, 3, 128, 128])\n",
      "tensor([1, 0, 1, 1, 0], device='cuda:0')\n",
      "28056\n",
      "28204\n",
      "28423\n",
      "28638\n",
      "28763\n",
      "torch.Size([5, 400, 3, 128, 128])\n",
      "tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "28913\n",
      "29029\n",
      "29197\n",
      "29365\n",
      "29449\n",
      "torch.Size([5, 400, 3, 128, 128])\n",
      "tensor([0, 0, 1, 1, 1], device='cuda:0')\n",
      "29551\n",
      "29707\n",
      "29988\n",
      "30123\n",
      "30384\n",
      "torch.Size([5, 400, 3, 128, 128])\n",
      "tensor([1, 1, 1, 1, 0], device='cuda:0')\n",
      "30645\n",
      "30926\n",
      "31051\n",
      "31202\n",
      "31418\n",
      "torch.Size([5, 400, 3, 128, 128])\n",
      "tensor([0, 1, 1, 0, 1], device='cuda:0')\n",
      "31708\n",
      "31868\n",
      "31993\n",
      "32199\n",
      "32364\n",
      "torch.Size([5, 400, 3, 128, 128])\n",
      "tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "32536\n",
      "32642\n",
      "32793\n",
      "32880\n",
      "33038\n",
      "torch.Size([5, 400, 3, 128, 128])\n",
      "tensor([1, 1, 1, 1, 0], device='cuda:0')\n",
      "33185\n",
      "33351\n",
      "33601\n",
      "33844\n",
      "33989\n",
      "torch.Size([5, 400, 3, 128, 128])\n",
      "tensor([0, 1, 1, 0, 1], device='cuda:0')\n",
      "34095\n",
      "34296\n",
      "34418\n",
      "34645\n",
      "34792\n",
      "torch.Size([5, 400, 3, 128, 128])\n",
      "tensor([1, 0, 0, 1, 1], device='cuda:0')\n",
      "34952\n",
      "35063\n",
      "35190\n",
      "35318\n",
      "35444\n",
      "torch.Size([5, 400, 3, 128, 128])\n",
      "tensor([1, 1, 0, 0, 1], device='cuda:0')\n",
      "35551\n",
      "35730\n",
      "35846\n",
      "35962\n",
      "36100\n",
      "torch.Size([5, 400, 3, 128, 128])\n",
      "tensor([0, 1, 1, 0, 1], device='cuda:0')\n",
      "36229\n",
      "36390\n",
      "36609\n",
      "36798\n",
      "37037\n",
      "torch.Size([5, 400, 3, 128, 128])\n",
      "tensor([0, 1, 1, 0, 1], device='cuda:0')\n",
      "37158\n",
      "37312\n",
      "37503\n",
      "37647\n",
      "37753\n",
      "torch.Size([5, 400, 3, 128, 128])\n",
      "tensor([1, 0, 1, 1, 0], device='cuda:0')\n",
      "38122\n",
      "38314\n",
      "38467\n",
      "38591\n",
      "38727\n",
      "torch.Size([5, 400, 3, 128, 128])\n",
      "tensor([0, 1, 0, 1, 0], device='cuda:0')\n",
      "39054\n",
      "39156\n",
      "39328\n",
      "39555\n",
      "39714\n",
      "torch.Size([5, 400, 3, 128, 128])\n",
      "tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "39845\n",
      "39995\n",
      "40184\n",
      "40280\n",
      "40459\n",
      "torch.Size([5, 400, 3, 128, 128])\n",
      "tensor([0, 0, 1, 1, 1], device='cuda:0')\n",
      "40796\n",
      "40909\n",
      "41019\n",
      "41209\n",
      "41312\n",
      "torch.Size([5, 400, 3, 128, 128])\n",
      "tensor([1, 0, 1, 1, 1], device='cuda:0')\n",
      "41549\n",
      "41677\n",
      "41908\n",
      "42148\n",
      "42326\n",
      "torch.Size([5, 400, 3, 128, 128])\n",
      "tensor([0, 0, 0, 1, 1], device='cuda:0')\n",
      "42485\n",
      "42691\n",
      "42870\n",
      "42984\n",
      "43161\n",
      "torch.Size([5, 400, 3, 128, 128])\n",
      "tensor([0, 1, 0, 1, 0], device='cuda:0')\n",
      "43292\n",
      "43395\n",
      "43544\n",
      "43716\n",
      "43952\n",
      "torch.Size([5, 400, 3, 128, 128])\n",
      "tensor([0, 1, 1, 0, 0], device='cuda:0')\n",
      "44099\n",
      "44247\n",
      "44366\n",
      "44600\n",
      "44740\n",
      "torch.Size([5, 400, 3, 128, 128])\n",
      "tensor([0, 0, 0, 0, 1], device='cuda:0')\n",
      "44869\n",
      "44985\n",
      "45176\n",
      "45379\n",
      "45561\n",
      "torch.Size([5, 400, 3, 128, 128])\n",
      "tensor([0, 0, 1, 1, 1], device='cuda:0')\n",
      "45782\n",
      "45964\n",
      "46193\n",
      "46333\n",
      "46495\n",
      "torch.Size([5, 400, 3, 128, 128])\n",
      "tensor([1, 1, 1, 1, 0], device='cuda:0')\n",
      "46663\n",
      "46752\n",
      "46863\n",
      "47049\n",
      "47220\n",
      "torch.Size([5, 400, 3, 128, 128])\n",
      "tensor([1, 1, 0, 0, 1], device='cuda:0')\n",
      "47367\n",
      "47546\n",
      "47724\n",
      "47943\n",
      "48048\n",
      "torch.Size([5, 400, 3, 128, 128])\n",
      "tensor([0, 1, 1, 1, 1], device='cuda:0')\n",
      "48182\n",
      "48361\n",
      "48612\n",
      "48715\n",
      "48846\n",
      "torch.Size([5, 400, 3, 128, 128])\n",
      "tensor([0, 1, 1, 1, 0], device='cuda:0')\n",
      "49015\n",
      "49245\n",
      "49394\n",
      "49669\n",
      "49785\n",
      "torch.Size([5, 400, 3, 128, 128])\n",
      "tensor([0, 1, 0, 1, 1], device='cuda:0')\n",
      "49950\n",
      "50115\n",
      "50277\n",
      "50431\n",
      "50557\n",
      "torch.Size([5, 400, 3, 128, 128])\n",
      "tensor([1, 0, 1, 0, 1], device='cuda:0')\n",
      "50789\n",
      "50950\n",
      "51046\n",
      "51273\n",
      "51432\n",
      "torch.Size([5, 400, 3, 128, 128])\n",
      "tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "51726\n",
      "51842\n",
      "52056\n",
      "52172\n",
      "52361\n",
      "torch.Size([5, 400, 3, 128, 128])\n",
      "tensor([1, 1, 1, 0, 0], device='cuda:0')\n",
      "52488\n",
      "52636\n",
      "52839\n",
      "53080\n",
      "53210\n",
      "torch.Size([5, 400, 3, 128, 128])\n",
      "tensor([0, 1, 1, 1, 0], device='cuda:0')\n",
      "53425\n",
      "53591\n",
      "53687\n",
      "53849\n",
      "53962\n",
      "torch.Size([5, 400, 3, 128, 128])\n",
      "tensor([1, 1, 1, 0, 1], device='cuda:0')\n",
      "54130\n",
      "54289\n",
      "54427\n",
      "54633\n",
      "54777\n",
      "torch.Size([5, 400, 3, 128, 128])\n",
      "tensor([1, 0, 0, 0, 1], device='cuda:0')\n",
      "54937\n",
      "55115\n",
      "55217\n",
      "55379\n",
      "55539\n",
      "torch.Size([5, 400, 3, 128, 128])\n",
      "tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "55677\n",
      "55813\n",
      "55949\n",
      "56179\n",
      "56377\n",
      "torch.Size([5, 400, 3, 128, 128])\n",
      "tensor([1, 1, 0, 1, 0], device='cuda:0')\n",
      "56499\n",
      "56646\n",
      "56852\n",
      "57091\n",
      "57241\n",
      "torch.Size([5, 400, 3, 128, 128])\n",
      "tensor([0, 1, 0, 1, 1], device='cuda:0')\n",
      "57365\n",
      "57520\n",
      "57663\n",
      "57855\n",
      "58289\n",
      "torch.Size([5, 400, 3, 128, 128])\n",
      "tensor([1, 1, 1, 0, 1], device='cuda:0')\n",
      "58411\n",
      "58597\n",
      "58746\n",
      "58996\n",
      "59139\n",
      "torch.Size([5, 400, 3, 128, 128])\n",
      "tensor([1, 0, 1, 1, 1], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "path ='/home/subru/projects/CNN/A-Dataset-for-Automatic-Violence-Detection-in-Videos-master/violence-detection-dataset'\n",
    "train_dataset = VideoDataset(root_dir=path, transform=transform)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=5, shuffle=True)\n",
    "\n",
    "# Iterate through the data loader\n",
    "for videos, labels in train_loader:\n",
    "    print(videos.shape)  # Should print shape [batch_size, frames, channels, height, width]\n",
    "    print(labels)        # Should print corresponding labels (0 for non-violent, 1 for violent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Total Frames: 59139\n",
    "##### Average frames per video: 169"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

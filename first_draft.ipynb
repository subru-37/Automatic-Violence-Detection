{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torchvision.io as io\n",
    "import os\n",
    "\n",
    "# Define your device (for GPU processing)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device: \", device)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    # transforms.ToPILImage(),\n",
    "    transforms.Resize((128, 128)),  # Resize frames to 128x128\n",
    "    transforms.ToTensor(),  # Convert frames to tensor format\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize the RGB channels\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "class VideoDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None, max_frames=240, train=True, test_size=0.2):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.max_frames = max_frames\n",
    "        self.classes = ['non_violent', 'violent']\n",
    "        self.data = []\n",
    "\n",
    "        # Load all data\n",
    "        for label, class_name in enumerate(self.classes):\n",
    "            class_dir = os.path.join(root_dir, class_name)\n",
    "            for cam_folder in os.listdir(class_dir):\n",
    "                cam_dir = os.path.join(class_dir, cam_folder)\n",
    "                if os.path.isdir(cam_dir):\n",
    "                    for video_name in os.listdir(cam_dir):\n",
    "                        if video_name.endswith('.mp4'):\n",
    "                            video_path = os.path.join(cam_dir, video_name)\n",
    "                            self.data.append((video_path, label))\n",
    "\n",
    "        # Split data into training and testing sets\n",
    "        train_data, test_data = train_test_split(self.data, test_size=test_size, stratify=[x[1] for x in self.data])\n",
    "\n",
    "        # Select either train or test data\n",
    "        if train:\n",
    "            self.data = train_data\n",
    "        else:\n",
    "            self.data = test_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        video_path, label = self.data[idx]\n",
    "        \n",
    "        # Load the video and process frames as you already do\n",
    "        video, _, _ = io.read_video(video_path, pts_unit='sec')\n",
    "\n",
    "        # Perform the padding or truncating of frames\n",
    "        total_frames = video.shape[0]\n",
    "        if total_frames < self.max_frames:\n",
    "            padded_video = torch.zeros((self.max_frames, video.shape[1], video.shape[2], video.shape[3]), dtype=video.dtype)\n",
    "            padded_video[:total_frames] = video\n",
    "            video = padded_video\n",
    "        else:\n",
    "            video = video[:self.max_frames]\n",
    "\n",
    "        # Apply transformations\n",
    "        pil_transform = transforms.ToPILImage()\n",
    "        frames = [self.transform(pil_transform(frame.permute(2, 0, 1))) for frame in video] if self.transform else video\n",
    "        video = torch.stack(frames).permute(1, 0, 2, 3).to(device)\n",
    "        label = torch.tensor(label).to(device)\n",
    "        return video, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 0], device='cuda:0')\n",
      "2\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 0], device='cuda:0')\n",
      "4\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 1], device='cuda:0')\n",
      "6\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 0], device='cuda:0')\n",
      "8\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 1], device='cuda:0')\n",
      "10\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([0, 1], device='cuda:0')\n",
      "12\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 1], device='cuda:0')\n",
      "14\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 0], device='cuda:0')\n",
      "16\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 0], device='cuda:0')\n",
      "18\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 0], device='cuda:0')\n",
      "20\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([0, 1], device='cuda:0')\n",
      "22\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 1], device='cuda:0')\n",
      "24\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 0], device='cuda:0')\n",
      "26\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([0, 0], device='cuda:0')\n",
      "28\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 1], device='cuda:0')\n",
      "30\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 0], device='cuda:0')\n",
      "32\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 1], device='cuda:0')\n",
      "34\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 1], device='cuda:0')\n",
      "36\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 0], device='cuda:0')\n",
      "38\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([0, 1], device='cuda:0')\n",
      "40\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 1], device='cuda:0')\n",
      "42\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 0], device='cuda:0')\n",
      "44\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([0, 0], device='cuda:0')\n",
      "46\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 0], device='cuda:0')\n",
      "48\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 1], device='cuda:0')\n",
      "50\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 1], device='cuda:0')\n",
      "52\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([0, 1], device='cuda:0')\n",
      "54\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 1], device='cuda:0')\n",
      "56\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([0, 1], device='cuda:0')\n",
      "58\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([0, 0], device='cuda:0')\n",
      "60\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 0], device='cuda:0')\n",
      "62\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 0], device='cuda:0')\n",
      "64\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 1], device='cuda:0')\n",
      "66\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([0, 0], device='cuda:0')\n",
      "68\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([0, 1], device='cuda:0')\n",
      "70\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 1], device='cuda:0')\n",
      "72\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([0, 1], device='cuda:0')\n",
      "74\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([0, 1], device='cuda:0')\n",
      "76\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 1], device='cuda:0')\n",
      "78\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 1], device='cuda:0')\n",
      "80\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 1], device='cuda:0')\n",
      "82\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 1], device='cuda:0')\n",
      "84\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([0, 0], device='cuda:0')\n",
      "86\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([0, 1], device='cuda:0')\n",
      "88\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 1], device='cuda:0')\n",
      "90\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([0, 1], device='cuda:0')\n",
      "92\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([0, 1], device='cuda:0')\n",
      "94\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 1], device='cuda:0')\n",
      "96\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 1], device='cuda:0')\n",
      "98\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 1], device='cuda:0')\n",
      "100\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 0], device='cuda:0')\n",
      "102\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([0, 1], device='cuda:0')\n",
      "104\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 1], device='cuda:0')\n",
      "106\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 1], device='cuda:0')\n",
      "108\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([0, 1], device='cuda:0')\n",
      "110\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 0], device='cuda:0')\n",
      "112\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 1], device='cuda:0')\n",
      "114\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 1], device='cuda:0')\n",
      "116\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 0], device='cuda:0')\n",
      "118\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([0, 1], device='cuda:0')\n",
      "120\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 1], device='cuda:0')\n",
      "122\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([0, 1], device='cuda:0')\n",
      "124\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([0, 0], device='cuda:0')\n",
      "126\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([0, 0], device='cuda:0')\n",
      "128\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 0], device='cuda:0')\n",
      "130\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 0], device='cuda:0')\n",
      "132\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 0], device='cuda:0')\n",
      "134\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([0, 1], device='cuda:0')\n",
      "136\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 1], device='cuda:0')\n",
      "138\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 0], device='cuda:0')\n",
      "140\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 1], device='cuda:0')\n",
      "142\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 1], device='cuda:0')\n",
      "144\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 1], device='cuda:0')\n",
      "146\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 0], device='cuda:0')\n",
      "148\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 1], device='cuda:0')\n",
      "150\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 1], device='cuda:0')\n",
      "152\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 1], device='cuda:0')\n",
      "154\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 0], device='cuda:0')\n",
      "156\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 0], device='cuda:0')\n",
      "158\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([0, 1], device='cuda:0')\n",
      "160\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 1], device='cuda:0')\n",
      "162\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 1], device='cuda:0')\n",
      "164\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 0], device='cuda:0')\n",
      "166\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 0], device='cuda:0')\n",
      "168\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 0], device='cuda:0')\n",
      "170\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 1], device='cuda:0')\n",
      "172\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([0, 0], device='cuda:0')\n",
      "174\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 1], device='cuda:0')\n",
      "176\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([0, 0], device='cuda:0')\n",
      "178\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 0], device='cuda:0')\n",
      "180\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 1], device='cuda:0')\n",
      "182\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([0, 1], device='cuda:0')\n",
      "184\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 1], device='cuda:0')\n",
      "186\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([0, 1], device='cuda:0')\n",
      "188\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 0], device='cuda:0')\n",
      "190\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([0, 1], device='cuda:0')\n",
      "192\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 1], device='cuda:0')\n",
      "194\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 1], device='cuda:0')\n",
      "196\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 1], device='cuda:0')\n",
      "198\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 1], device='cuda:0')\n",
      "200\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([0, 0], device='cuda:0')\n",
      "202\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 1], device='cuda:0')\n",
      "204\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 1], device='cuda:0')\n",
      "206\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([0, 1], device='cuda:0')\n",
      "208\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([0, 0], device='cuda:0')\n",
      "210\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 0], device='cuda:0')\n",
      "212\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 1], device='cuda:0')\n",
      "214\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([0, 1], device='cuda:0')\n",
      "216\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 1], device='cuda:0')\n",
      "218\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 1], device='cuda:0')\n",
      "220\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 1], device='cuda:0')\n",
      "222\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 1], device='cuda:0')\n",
      "224\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([0, 0], device='cuda:0')\n",
      "226\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([0, 1], device='cuda:0')\n",
      "228\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([0, 0], device='cuda:0')\n",
      "230\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 1], device='cuda:0')\n",
      "232\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 1], device='cuda:0')\n",
      "234\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 1], device='cuda:0')\n",
      "236\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([0, 1], device='cuda:0')\n",
      "238\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 0], device='cuda:0')\n",
      "240\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([0, 0], device='cuda:0')\n",
      "242\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([0, 0], device='cuda:0')\n",
      "244\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 1], device='cuda:0')\n",
      "246\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([0, 1], device='cuda:0')\n",
      "248\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([0, 0], device='cuda:0')\n",
      "250\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([0, 1], device='cuda:0')\n",
      "252\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 0], device='cuda:0')\n",
      "254\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 0], device='cuda:0')\n",
      "256\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([0, 1], device='cuda:0')\n",
      "258\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([0, 1], device='cuda:0')\n",
      "260\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 1], device='cuda:0')\n",
      "262\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 1], device='cuda:0')\n",
      "264\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 1], device='cuda:0')\n",
      "266\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 1], device='cuda:0')\n",
      "268\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([0, 0], device='cuda:0')\n",
      "270\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 1], device='cuda:0')\n",
      "272\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([0, 1], device='cuda:0')\n",
      "274\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 1], device='cuda:0')\n",
      "276\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 0], device='cuda:0')\n",
      "278\n",
      "torch.Size([2, 3, 240, 128, 128])\n",
      "tensor([1, 1], device='cuda:0')\n",
      "280\n"
     ]
    }
   ],
   "source": [
    "path ='/home/subru/projects/CNN/A-Dataset-for-Automatic-Violence-Detection-in-Videos-master/violence-detection-dataset'\n",
    "# train_dataset = VideoDataset(root_dir=path, transform=transform)\n",
    "\n",
    "# Create data loaders\n",
    "# train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
    "train_dataset = VideoDataset(root_dir=path, transform=transform, train=True, test_size=0.2)\n",
    "test_dataset = VideoDataset(root_dir=path, transform=transform, train=False, test_size=0.2)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "# Iterate through the data loader\n",
    "i = 1\n",
    "for videos, labels in train_loader:\n",
    "    print(videos.shape)  # Should print shape [batch_size, frames, channels, height, width]\n",
    "    print(labels)        # Should print corresponding labels (0 for non-violent, 1 for violent)\n",
    "    print(i*2)\n",
    "    i+=1\n",
    "test_loader = DataLoader(test_dataset, batch_size=2, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Total Frames: 59139\n",
    "##### Average frames per video: 169\n",
    "##### Time to load 350 videos: 43m 26.0s\n",
    "##### VRAM used: 1190MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subru/projects/CNN/mytorch/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/subru/projects/CNN/mytorch/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=R3D_18_Weights.KINETICS400_V1`. You can also use `weights=R3D_18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from torchvision.models.video import r3d_18\n",
    "\n",
    "# Load the pre-trained ResNet3D-18 model\n",
    "model = r3d_18(pretrained=True)\n",
    "\n",
    "# Modify the last fully connected layer for 2 classes (binary classification)\n",
    "model.fc = nn.Linear(in_features=model.fc.in_features, out_features=2)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Unfreeze the final fully connected layer\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.fc.parameters(), lr=0.0001)  # Only train final layer\n",
    "# train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9664/3457622850.py:3: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scalar = GradScaler('cuda')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25], Loss: 0.0008009956351348332\n"
     ]
    }
   ],
   "source": [
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "scalar = GradScaler('cuda')\n",
    "\n",
    "accumulation_steps = 4\n",
    "for epoch in range(25):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    optimizer.zero_grad()\n",
    "    # train_dataset\n",
    "    i = 0\n",
    "    for videos, labels in train_loader:\n",
    "        videos, labels = videos.to(device), labels.to(device)\n",
    "        # print(videos.shape)\n",
    "        # print(batch_idx.shape)\n",
    "        # Forward pass\n",
    "        # with autocast(enabled=True):    \n",
    "        outputs = model(videos)\n",
    "        loss = criterion(outputs, labels)/ accumulation_steps\n",
    "         \n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        if (i + 1) % accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "                    # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "        i+=1\n",
    "    running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{25}], Loss: {running_loss/len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for videos, labels in test_loader:\n",
    "        videos, labels = videos.to(device), labels.to(device)\n",
    "        outputs = model(videos)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Accuracy: {100 * correct / total}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
